
### **Target Variable**
- `exam_score`

### **Feature Types**

#### ğŸ”¹ Numerical Features  
- `age`  
- `study_hours`  
- `class_attendance`  
- `sleep_hours`  

#### ğŸ”¸ Ordinal Categorical Features  
- `sleep_quality` â†’ poor < average < good < excellent  
- `facility_rating` â†’ low < medium < high  
- `exam_difficulty` â†’ easy < medium < hard  

#### ğŸ”¹ Nominal Categorical Features  
- `gender`  
- `course`  
- `internet_access`  
- `study_method`  

---

## ğŸ› ï¸ Technologies & Libraries

- **Python 3.x**
- **Pandas** â€“ data manipulation  
- **NumPy**  
- **Matplotlib & Seaborn** â€“ visual analysis  
- **Scikit-Learn**  
  - `OrdinalEncoder`  
  - `OneHotEncoder`  
  - `ColumnTransformer`  
  - `StandardScaler`  
  - `train_test_split`  

---

## ğŸ“‘ Notebook Workflow Summary

### **1. Data Loading & Inspection**
- Inspect first rows with `.head()`  
- Check dataset structure (`.info()`)  
- Identify missing values & duplicates  
- Basic statistics via `.describe()`  

### **2. Exploratory Data Analysis (EDA)**
- Numerical feature distributions  
- Correlation heatmap  
- Category spread & uniqueness checks  

### **3. Preprocessing & Feature Engineering**
- Split dataset into training and testing sets  
- Apply **Ordinal Encoding** with defined category order  
- Apply **One-Hot Encoding** for nominal features  
- Scale numerical features using **StandardScaler**  
- Integrate transformations using **ColumnTransformer**  
- Export final processed feature sets for modeling  

---

## ğŸ“¦ Output Artifacts

The notebook produces the following key objects:

- `X_train_df` â€” processed training features  
- `X_test_df` â€” processed testing features  
- Encoded, scaled, and cleaned datasets  
- Reconstructed feature names  
- A complete preprocessing pipeline ready for ML modeling  

---

## â–¶ï¸ How to Use

Clone the repository:

```bash
git clone <your-repo-url>
cd <repository-folder>
